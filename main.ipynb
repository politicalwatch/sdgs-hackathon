{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: move to requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop-words in c:\\users\\saox\\anaconda3\\lib\\site-packages (2018.7.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\saox\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\saox\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\saox\\appdata\\roaming\\python\\python37\\site-packages (from wordcloud) (8.1.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from wordcloud) (1.19.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\saox\\appdata\\roaming\\python\\python37\\site-packages (from wordcloud) (3.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\saox\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\saox\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in c:\\users\\saox\\anaconda3\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\saox\\anaconda3\\lib\\site-packages (from stanza) (1.19.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\saox\\anaconda3\\lib\\site-packages (from stanza) (3.11.3)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from stanza) (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\saox\\appdata\\roaming\\python\\python37\\site-packages (from stanza) (2.25.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saox\\anaconda3\\lib\\site-packages (from stanza) (4.54.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\saox\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saox\\anaconda3\\lib\\site-packages (from protobuf->stanza) (51.0.0.post20201207)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from protobuf->stanza) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from requests->stanza) (2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\saox\\appdata\\roaming\\python\\python37\\site-packages (from requests->stanza) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\saox\\appdata\\roaming\\python\\python37\\site-packages (from requests->stanza) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from requests->stanza) (2020.12.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\saox\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy-stanza in c:\\users\\saox\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy-stanza) (3.1.3)\n",
      "Requirement already satisfied: stanza<1.3.0,>=1.2.0 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy-stanza) (1.2.3)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.7.4.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\saox\\appdata\\roaming\\python\\python37\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\saox\\appdata\\roaming\\python\\python37\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (20.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (51.0.0.post20201207)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (4.54.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (8.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.5)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.19.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (2.11.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (1.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.6.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (0.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-stanza) (3.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy<4.0.0,>=3.0.0->spacy-stanza) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.0.0->spacy-stanza) (5.2.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\saox\\appdata\\roaming\\python\\python37\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\saox\\appdata\\roaming\\python\\python37\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (1.25.11)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from stanza<1.3.0,>=1.2.0->spacy-stanza) (1.7.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\saox\\anaconda3\\lib\\site-packages (from stanza<1.3.0,>=1.2.0->spacy-stanza) (3.11.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-stanza) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy-stanza) (1.1.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\saox\\anaconda3\\lib\\site-packages (from protobuf->stanza<1.3.0,>=1.2.0->spacy-stanza) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\saox\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install stop-words\n",
    "!pip install wordcloud\n",
    "!pip install stanza\n",
    "!pip install spacy-stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# Download the stanza model if necessary\n",
    "stanza.download(\"es\")\n",
    "\n",
    "# Initialize the pipeline\n",
    "nlp = spacy_stanza.load_pipeline(\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unidecode\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords as swords\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import stanza\n",
    "import spacy_stanza\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('initiatives.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>author_parliamentarygroups</th>\n",
       "      <th>created</th>\n",
       "      <th>initiative_type</th>\n",
       "      <th>initiative_type_alt</th>\n",
       "      <th>reference</th>\n",
       "      <th>status</th>\n",
       "      <th>tagged</th>\n",
       "      <th>title</th>\n",
       "      <th>updated</th>\n",
       "      <th>url</th>\n",
       "      <th>tags</th>\n",
       "      <th>topics</th>\n",
       "      <th>history</th>\n",
       "      <th>author_others</th>\n",
       "      <th>place</th>\n",
       "      <th>content</th>\n",
       "      <th>extra</th>\n",
       "      <th>author_deputies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8340a50c3e322491545cf6c40b0b3d29ed03cb85</td>\n",
       "      <td>[Grupo Parlamentario Ciudadanos]</td>\n",
       "      <td>{'$date': '2020-06-02T00:00:00Z'}</td>\n",
       "      <td>84</td>\n",
       "      <td>Moción de reprobación a miembros del Gobierno</td>\n",
       "      <td>084/000004</td>\n",
       "      <td>Desconocida</td>\n",
       "      <td>True</td>\n",
       "      <td>Reprobación del Ministro del Interior, don Fer...</td>\n",
       "      <td>{'$date': '2020-06-09T00:00:00Z'}</td>\n",
       "      <td>https://www.congreso.es/web/guest/indice-de-in...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06709837ef704e5aaacfa6ea400517c560ebdd53</td>\n",
       "      <td>[Grupo Parlamentario Republicano]</td>\n",
       "      <td>{'$date': '2021-03-18T00:00:00Z'}</td>\n",
       "      <td>84</td>\n",
       "      <td>Moción de reprobación a miembros del Gobierno</td>\n",
       "      <td>084/000022</td>\n",
       "      <td>Desconocida</td>\n",
       "      <td>True</td>\n",
       "      <td>Reprobación de la Ministra de Defensa.</td>\n",
       "      <td>{'$date': '2021-03-23T00:00:00Z'}</td>\n",
       "      <td>https://www.congreso.es/web/guest/indice-de-in...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08cee188414ee529ca4dc998340791bae832029f</td>\n",
       "      <td>[Grupo Parlamentario Popular]</td>\n",
       "      <td>{'$date': '2021-03-25T00:00:00Z'}</td>\n",
       "      <td>84</td>\n",
       "      <td>Moción de reprobación a miembros del Gobierno</td>\n",
       "      <td>084/000023</td>\n",
       "      <td>Desconocida</td>\n",
       "      <td>True</td>\n",
       "      <td>Reprobación de la Ministra de Educación y Form...</td>\n",
       "      <td>{'$date': '2021-04-06T00:00:00Z'}</td>\n",
       "      <td>https://www.congreso.es/web/guest/indice-de-in...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70e6ca135dfb404955c15cf109c2a3614951528f</td>\n",
       "      <td>[Grupo Parlamentario Ciudadanos]</td>\n",
       "      <td>{'$date': '2021-02-08T00:00:00Z'}</td>\n",
       "      <td>84</td>\n",
       "      <td>Moción de reprobación a miembros del Gobierno</td>\n",
       "      <td>084/000021</td>\n",
       "      <td>Desconocida</td>\n",
       "      <td>True</td>\n",
       "      <td>Reprobación del Vicepresidente Segundo del Gob...</td>\n",
       "      <td>{'$date': '2021-02-16T00:00:00Z'}</td>\n",
       "      <td>https://www.congreso.es/web/guest/indice-de-in...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48643b81ce1cd97cbe74ceb711eaafb7ead9241f</td>\n",
       "      <td>[Grupo Parlamentario Popular]</td>\n",
       "      <td>{'$date': '2020-06-02T00:00:00Z'}</td>\n",
       "      <td>84</td>\n",
       "      <td>Moción de reprobación a miembros del Gobierno</td>\n",
       "      <td>084/000003</td>\n",
       "      <td>Desconocida</td>\n",
       "      <td>True</td>\n",
       "      <td>Reprobación del Ministro del Interior.</td>\n",
       "      <td>{'$date': '2020-06-09T00:00:00Z'}</td>\n",
       "      <td>https://www.congreso.es/web/guest/indice-de-in...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        _id  \\\n",
       "0  8340a50c3e322491545cf6c40b0b3d29ed03cb85   \n",
       "1  06709837ef704e5aaacfa6ea400517c560ebdd53   \n",
       "2  08cee188414ee529ca4dc998340791bae832029f   \n",
       "3  70e6ca135dfb404955c15cf109c2a3614951528f   \n",
       "4  48643b81ce1cd97cbe74ceb711eaafb7ead9241f   \n",
       "\n",
       "          author_parliamentarygroups                            created  \\\n",
       "0   [Grupo Parlamentario Ciudadanos]  {'$date': '2020-06-02T00:00:00Z'}   \n",
       "1  [Grupo Parlamentario Republicano]  {'$date': '2021-03-18T00:00:00Z'}   \n",
       "2      [Grupo Parlamentario Popular]  {'$date': '2021-03-25T00:00:00Z'}   \n",
       "3   [Grupo Parlamentario Ciudadanos]  {'$date': '2021-02-08T00:00:00Z'}   \n",
       "4      [Grupo Parlamentario Popular]  {'$date': '2020-06-02T00:00:00Z'}   \n",
       "\n",
       "   initiative_type                            initiative_type_alt   reference  \\\n",
       "0               84  Moción de reprobación a miembros del Gobierno  084/000004   \n",
       "1               84  Moción de reprobación a miembros del Gobierno  084/000022   \n",
       "2               84  Moción de reprobación a miembros del Gobierno  084/000023   \n",
       "3               84  Moción de reprobación a miembros del Gobierno  084/000021   \n",
       "4               84  Moción de reprobación a miembros del Gobierno  084/000003   \n",
       "\n",
       "        status  tagged                                              title  \\\n",
       "0  Desconocida    True  Reprobación del Ministro del Interior, don Fer...   \n",
       "1  Desconocida    True             Reprobación de la Ministra de Defensa.   \n",
       "2  Desconocida    True  Reprobación de la Ministra de Educación y Form...   \n",
       "3  Desconocida    True  Reprobación del Vicepresidente Segundo del Gob...   \n",
       "4  Desconocida    True             Reprobación del Ministro del Interior.   \n",
       "\n",
       "                             updated  \\\n",
       "0  {'$date': '2020-06-09T00:00:00Z'}   \n",
       "1  {'$date': '2021-03-23T00:00:00Z'}   \n",
       "2  {'$date': '2021-04-06T00:00:00Z'}   \n",
       "3  {'$date': '2021-02-16T00:00:00Z'}   \n",
       "4  {'$date': '2020-06-09T00:00:00Z'}   \n",
       "\n",
       "                                                 url tags topics history  \\\n",
       "0  https://www.congreso.es/web/guest/indice-de-in...   []     []     NaN   \n",
       "1  https://www.congreso.es/web/guest/indice-de-in...   []     []     NaN   \n",
       "2  https://www.congreso.es/web/guest/indice-de-in...   []     []     NaN   \n",
       "3  https://www.congreso.es/web/guest/indice-de-in...   []     []     NaN   \n",
       "4  https://www.congreso.es/web/guest/indice-de-in...   []     []     NaN   \n",
       "\n",
       "  author_others place content extra author_deputies  \n",
       "0           NaN   NaN     NaN   NaN             NaN  \n",
       "1           NaN   NaN     NaN   NaN             NaN  \n",
       "2           NaN   NaN     NaN   NaN             NaN  \n",
       "3           NaN   NaN     NaN   NaN             NaN  \n",
       "4           NaN   NaN     NaN   NaN             NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If content is not present, use the title as content\n",
    "df['content_coalesce'] = df['content'].combine_first(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_coalesce</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reprobación del Ministro del Interior, don Fer...</td>\n",
       "      <td>Reprobación del Ministro del Interior, don Fer...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reprobación de la Ministra de Defensa.</td>\n",
       "      <td>Reprobación de la Ministra de Defensa.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reprobación de la Ministra de Educación y Form...</td>\n",
       "      <td>Reprobación de la Ministra de Educación y Form...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reprobación del Vicepresidente Segundo del Gob...</td>\n",
       "      <td>Reprobación del Vicepresidente Segundo del Gob...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reprobación del Ministro del Interior.</td>\n",
       "      <td>Reprobación del Ministro del Interior.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110187</th>\n",
       "      <td>Recurso de inconstitucionalidad número 2379/20...</td>\n",
       "      <td>Recurso de inconstitucionalidad número 2379/20...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110188</th>\n",
       "      <td>Sentencia dictada por el citado Tribunal en el...</td>\n",
       "      <td>Sentencia dictada por el citado Tribunal en el...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110189</th>\n",
       "      <td>Cuestión de inconstitucionalidad número 3523/2...</td>\n",
       "      <td>Cuestión de inconstitucionalidad número 3523/2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110190</th>\n",
       "      <td>Informe de Gestión del ejercicio 2020.</td>\n",
       "      <td>Informe de Gestión del ejercicio 2020.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110191</th>\n",
       "      <td>Remisión del dictamen motivado del citado Parl...</td>\n",
       "      <td>Remisión del dictamen motivado del citado Parl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13617 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         content_coalesce  \\\n",
       "0       Reprobación del Ministro del Interior, don Fer...   \n",
       "1                  Reprobación de la Ministra de Defensa.   \n",
       "2       Reprobación de la Ministra de Educación y Form...   \n",
       "3       Reprobación del Vicepresidente Segundo del Gob...   \n",
       "4                  Reprobación del Ministro del Interior.   \n",
       "...                                                   ...   \n",
       "110187  Recurso de inconstitucionalidad número 2379/20...   \n",
       "110188  Sentencia dictada por el citado Tribunal en el...   \n",
       "110189  Cuestión de inconstitucionalidad número 3523/2...   \n",
       "110190             Informe de Gestión del ejercicio 2020.   \n",
       "110191  Remisión del dictamen motivado del citado Parl...   \n",
       "\n",
       "                                                    title content  \n",
       "0       Reprobación del Ministro del Interior, don Fer...     NaN  \n",
       "1                  Reprobación de la Ministra de Defensa.     NaN  \n",
       "2       Reprobación de la Ministra de Educación y Form...     NaN  \n",
       "3       Reprobación del Vicepresidente Segundo del Gob...     NaN  \n",
       "4                  Reprobación del Ministro del Interior.     NaN  \n",
       "...                                                   ...     ...  \n",
       "110187  Recurso de inconstitucionalidad número 2379/20...     NaN  \n",
       "110188  Sentencia dictada por el citado Tribunal en el...     NaN  \n",
       "110189  Cuestión de inconstitucionalidad número 3523/2...     NaN  \n",
       "110190             Informe de Gestión del ejercicio 2020.     NaN  \n",
       "110191  Remisión del dictamen motivado del citado Parl...     NaN  \n",
       "\n",
       "[13617 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "df[df['content'].isna()][['content_coalesce','title','content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we flatten and then create lists of the individual words\n",
    "# df['lists_content_coalesce'] = [''.join(l).split(\" \") for l in df['content_coalesce']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS FLATTENS\n",
    "df['content_coalesce'] = [''.join(l) for l in df['content_coalesce']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_json(file_path, columns_to_keep=['content','title','initiative_type_alt'],field_name='initiatives'):\n",
    "    with open(file_path,'r', encoding=\"utf8\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    data_frame = pd.json_normalize(data,record_path=field_name)\n",
    "    data_frame = data_frame[columns_to_keep]\n",
    "    return(data_frame)\n",
    "\n",
    "def retrieve_stop_words():\n",
    "    spanish_stopwords = swords.words('spanish')\n",
    "    stop_words_spanish = get_stop_words('spanish')\n",
    "    stopwords = list(set(spanish_stopwords + stop_words_spanish))\n",
    "    return stopwords\n",
    "\n",
    "def space_out_your_text(row):\n",
    "    doc = nlp(row)\n",
    "    cleaned = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in (\"PUNCT\",\"ADP\",\"SCONJ\",\"PRON\",\"CCONJ\"):\n",
    "            #print(token.text, token.lemma_, token.pos_, token.dep_)\n",
    "            cleaned+=token.lemma_+\" \"\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def remove_accents(row,column):\n",
    "    return unidecode.unidecode(row[column])\n",
    "\n",
    "#remove special characters\n",
    "def replace_special_char(row):\n",
    "    for word, initial in {\".\":\" \", \"-\":\" \",\"/\":\" \",\"@\":\" \",\"#\":\" \",\"(\":\" \",\")\":\" \",'\"' : \"\"}.items():\n",
    "        row = row.replace(word, initial) \n",
    "    return row\n",
    "\n",
    "def remove_stopwords(row, stopwords):\n",
    "    removed_stopwords = \" \".join([word for word in row.split(\" \") if word not in stopwords and word.replace(\" \",\"\")!=\"\"])\n",
    "    return removed_stopwords\n",
    "\n",
    "\n",
    "def remove_numbers(col):\n",
    "    return col.str.replace('\\d+', '')\n",
    "\n",
    "\n",
    "def unique_words(col):\n",
    "    col.str.lower().str.findall(\"\\w+\")\n",
    "    unique = set()\n",
    "\n",
    "    for x in words:\n",
    "        unique.update(x)\n",
    "    return unique\n",
    "\n",
    "\n",
    "def word_count(df):\n",
    "    tf = df['text'].apply(lambda x: FreqDist(x)).sum(axis = 0)\n",
    "    tf2 = dict(tf)\n",
    "    data_items = tf2.items()\n",
    "    data_list = list(data_items)\n",
    "    freq_dataframe = pd.DataFrame(data_list)\n",
    "    freq_dataframe.columns = ['Word','Counts']\n",
    "    freq_dataframe = freq_dataframe.sort_values(by=\"Counts\",ascending=False)\n",
    "    pd.set_option(\"max_rows\", None)\n",
    "    return freq_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = retrieve_stop_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# example usage: test_df = create_df_from_json('./small-batch.json')\n",
    "test_df = create_df_from_json('small-batch.json') \n",
    "\n",
    "grouped = test_df.groupby(\"initiative_type_alt\")['content'].apply(lambda tags: ','.join(tags))\n",
    "\n",
    "def show_cloud(i):\n",
    "    text = grouped[i]\n",
    "    wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "for i, row in grouped.iteritems():\n",
    "    unique_id = i   \n",
    "    print(i)    \n",
    "    if len(grouped[i])>0:\n",
    "        show_cloud(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply transformations one-by-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-654eda0df021>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content_coalesce'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Nr of words: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-666f714e605d>\u001b[0m in \u001b[0;36munique_words\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0munique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0munique\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "unique = unique_words(df['content_coalesce'])\n",
    "print(\"Nr of words: \" + str(len(list(unique))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Reprobacion del Ministro del Interior, don Fer...\n",
       "1               Reprobacion de la Ministra de Defensa.\n",
       "2    Reprobacion de la Ministra de Educacion y Form...\n",
       "3    Reprobacion del Vicepresidente Segundo del Gob...\n",
       "4               Reprobacion del Ministro del Interior.\n",
       "Name: t1_no_accents, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['t1_no_accents'] = df.apply(lambda row:remove_accents(row,'content_coalesce'),axis=1)\n",
    "df['t1_no_accents'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Reprobacion del Ministro del Interior, don Fer...\n",
       "1               Reprobacion de la Ministra de Defensa.\n",
       "2    Reprobacion de la Ministra de Educacion y Form...\n",
       "3    Reprobacion del Vicepresidente Segundo del Gob...\n",
       "4               Reprobacion del Ministro del Interior.\n",
       "Name: t2_no_numbers, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['t2_no_numbers'] = remove_numbers(df['t1_no_accents']) \n",
    "df['t2_no_numbers'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Reprobacion del Ministro del Interior, don Fer...\n",
       "1               Reprobacion de la Ministra de Defensa \n",
       "2    Reprobacion de la Ministra de Educacion y Form...\n",
       "3    Reprobacion del Vicepresidente Segundo del Gob...\n",
       "4               Reprobacion del Ministro del Interior \n",
       "Name: t3_no_special_char, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['t3_no_special_char'] = df['t2_no_numbers'].apply(lambda row:replace_special_char(row))\n",
    "df['t3_no_special_char'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    reprobacion del ministro del interior, don fer...\n",
       "1               reprobacion de la ministra de defensa \n",
       "2    reprobacion de la ministra de educacion y form...\n",
       "3    reprobacion del vicepresidente segundo del gob...\n",
       "4               reprobacion del ministro del interior \n",
       "Name: t4_lowercase, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['t4_lowercase'] = df['t3_no_special_char'].str.lower()\n",
    "df['t4_lowercase'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"unigrams\"] = df[\"t4_lowercase\"].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"unigrams\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t5_stopwords_removed'] = df['t4_lowercase'].apply(lambda row:remove_stopwords(row, stop_words))\n",
    "df['t5_stopwords_removed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    return \" \".join([tok.lemma_ for tok in nlp.tokenizer(text) if not tok.is_stop])\n",
    "\n",
    "df['t6_lemmitization'] = df['t5_stopwords_removed'].apply(lambda x:lemmatize(x))\n",
    "df['t6_lemmitization'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t5_stopwords_removed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = unique_words(df['t3_no_special_char'])\n",
    "print(\"Nr of words: \" + str(len(list(unique))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = unique_words(df['t5_stopwords_removed'])\n",
    "print(\"Nr of words: \" + str(len(list(unique))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = unique_words(df['t6_lemmitization'])\n",
    "print(\"Nr of words: \" + str(len(list(unique))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df._id == \"8139ec1c206e10ba04dde86d3e06f2698e34b0a6\"]['content_coalesce'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform(df):\n",
    "#     df['content_coalesce'] = df.apply(lambda row:remove_accents(row,'content_coalesce'),axis=1)\n",
    "# a = transform(df)\n",
    "# a['content_coalesce'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuations, tabs, etc \n",
    "df.apply(lambda row:space_out_your_text(row['lowered']),axis=1)\n",
    "#Lower case\n",
    "df.apply(lambda row: row['text'].lower(), axis=1)\n",
    "df['removed_num'] = df.apply(lambda row: remove_numbers(row['text']), axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['tokenized_sents'] = df2.apply(lambda row: nlp(row['removed_num']), axis=1)\n",
    "df2['tokenized_sents_str'] = df2.tokenized_sents.apply(lambda x:str(x))\n",
    "\n",
    "infreq = freq_dataframe[freq_dataframe['Counts'] < 3 ]['Word'].tolist()\n",
    "\n",
    "\n",
    "df2['removed_infreq'] = df2.tokenized_sents_str.apply(lambda x: remove_stopwords(x,infreq))\n",
    "df2['removed_infreq_str'] = df2.removed_infreq.apply(lambda x:str(x))\n",
    "\n",
    "\n",
    "\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(df2['removed_infreq_str'])\n",
    "x.todense()\n",
    "len(v.vocabulary_)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
